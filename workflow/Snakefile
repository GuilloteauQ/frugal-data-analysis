
BENCHMARKS = [
  "cigri",
  "cigri-sorted"
]

SCRIPTING_LANGUAGES = {
  "R-tidyverse": "R",
  #"R-polars": "R",
  #"R-tidypolars": "R",
  "awk": "awk",
  "nushell" : "nushell",
  "mawk": "mawk",
  "miller": "miller",
  "duckdb": "duckdb",
  "datamash": "datamash",
  "python-pandas": "py",
  "python-polars": "py",
}

COMPILED_LANGUAGES = {
  "rust-polars" : "rs"
}

DATASETS = {
  "cigri": "datasets/data_cigri_2013_2023.csv",
  "cigri-sorted": "datasets/data_cigri_2013_2023_sorted.csv"
}

MAX_ITER = 3
ITERATIONS = range(0, MAX_ITER)

NB_ROWS = [i * 1000000 for i in range(1, 45, 10)] + [44577835]


rule all:
  input:
    "data/all/sizes.csv",
    "data/all/sizes_details.csv",
    "data/all/expes.csv",

rule get_size:
  input:
    "flake.nix",
    "workflow/envs/{lang}.nix",
    script="workflow/scripts/get_size_nix_env.py"
  output:
    "data/sizes/{lang}.csv"
  params:
    system = "aarch64-darwin"
    #system = "x86_64-linux"
  shell:
    "python3 {input.script} {wildcards.lang} {params.system} > {output}"

rule get_size_details:
  input:
    "flake.nix",
    "workflow/envs/{lang}.nix",
  output:
    "data/sizes/{lang}.dat"
  params:
    system = "aarch64-darwin"
    #system = "x86_64-linux"
  shell:
    "nix build .#devShells.{params.system}.{wildcards.lang} -o output_nix_build_{wildcards.lang} && nix-store -qR output_nix_build_{wildcards.lang} | sed -E 's/(.*)/du -bs \\1/' | bash | sed -E 's/[[:space:]]+/,/g' | sed -E 'sW/nix/store([^-]*)-(.*)W\\2,{wildcards.lang}W' > {output} && rm output_nix_build_{wildcards.lang}"

rule run_expe_scripting:
  input:
    script=lambda w: f"benchmarks/{w.bench}/{w.lang}/main.{SCRIPTING_LANGUAGES[w.lang]}",
    timing_script=lambda w: f"workflow/scripts/timing_{SCRIPTING_LANGUAGES[w.lang]}.sh",
  wildcard_constraints:
    bench="|".join(BENCHMARKS),
    lang="|".join(SCRIPTING_LANGUAGES.keys())
  params:
    dataset=lambda w: DATASETS[w.bench]
  output:
    "data/{bench}/{lang}/{iter}.dat"
  shell:
    "nix develop .#{wildcards.lang} --command bash {input.timing_script} {input.script} {params.dataset} {wildcards.bench} {wildcards.lang} > {output}"


rule run_expe_compiled:
  input:
    script=lambda w: f"benchmarks/{w.bench}/{w.lang}/src/main.{COMPILED_LANGUAGES[w.lang]}",
    timing_script=lambda w: f"workflow/scripts/timing_{COMPILED_LANGUAGES[w.lang]}.sh",
  wildcard_constraints:
    bench="|".join(BENCHMARKS),
    lang="|".join(COMPILED_LANGUAGES.keys())
  params:
    dataset=lambda w: DATASETS[w.bench]
  output:
    "data/{bench}/{lang}/{iter}.dat"
  shell:
    "nix shell .#{wildcards.bench}-{wildcards.lang} --command bash {input.timing_script} ./result/bin/{wildcards.lang} {params.dataset} {wildcards.bench} {wildcards.lang} > {output}"


rule merge_sizes:
  input:
    data=expand("data/sizes/{lang}.csv",lang=list(COMPILED_LANGUAGES.keys()) + list(SCRIPTING_LANGUAGES.keys()))
  output:
    "data/all/sizes.csv"
  shell:
    "cat {input.data} > {output}"

rule merge_sizes_details:
  input:
    data=expand("data/sizes/{lang}.dat",lang=list(COMPILED_LANGUAGES.keys()) + list(SCRIPTING_LANGUAGES.keys()) + ["empty"])
  output:
    "data/all/sizes_details.csv"
  shell:
    "cat {input.data} > {output}"

rule merge_expes:
  input:
    data=expand("data/{bench}/{lang}/{iter}.dat",\
           bench=BENCHMARKS,\
           lang=list(COMPILED_LANGUAGES.keys()) + list(SCRIPTING_LANGUAGES.keys()),\
           iter=ITERATIONS)
  output:
    "data/all/expes.csv"
  shell:
    "cat {input.data} > {output}"
